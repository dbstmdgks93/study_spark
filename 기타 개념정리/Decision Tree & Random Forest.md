





# Decision Tree

<img src="images/Decision%20Tree.png" alt="Decision Tree"  />

 

위의 그림은 타이타닉 생존자를 찾는 의사결정트리 모델이다.

최종적으로, 모든 승객에 대한 분류를 통해 생존확률을 예측할 수 있게된다.

숫자형 결과를 반환하는 것을 회귀나무(Regression Tree) 라고 하고, 범주형 결과를 반환하는 것을 분류나무(Classification Tree) 라고 한다. 의사결정트리를 만들기 위해서는 먼저 어떤 질문을 할 것인지, 어떤 순서로 질문을 할 것인지 정해야 한다.

가장 좋은 방법은 예측하려는 대상에 대해 가장 많은 정보를 담고 있는 질문을 고르는 것이다. 
'얼마만큼의 정보를 담고 있는가?' 를 엔트로피(entropy)라고 한다. 엔트로피는 보통 데이터의 불확실성을 나타내며, 결국 엔트로피가 클수록 데이터 정보가 잘 분포되어있기 때문에 좋은 지표라고 예상할 수 있다.

그림과 같이 의사결정트리는 이해하고 해석하기 쉽다는 장점이 있습니다. 또한 예측할 때 사용하는 프로세스가 명백하며, 숫자형 / 범주형 데이터를 동시에 다룰 수 있습니다. 그리고 특정 변수의 값이 누락되어도 사용할 수 있습니다.

하지만 최적의 의사결정트리를 찾는 것이 정말 어려운 문제입니다. (어떤 것들을 조건(Feature)으로 넣어야 할지, 깊이(Depth)는 얼마로 정해야 할지…) 그리고 의사결정트리의 단점은 새로운 데이터에 대한 일반화 성능이 좋지 않게 오버피팅(Overfitting)되기 쉽다는 것입니다.

잠깐 오버피팅에 대해 설명하자면, 오버피팅이란 Supervised Learning에서 과거의 학습한 데이터에 대해서는 잘 예측하지만 새로 들어온 데이터에 대해서 성능이 떨어지는 경우를 말합니다. 즉, 학습 데이터에 지나치게 최적화되어 일반화가 어렵다는 말입니다. 이러한 오버피팅을 방지할 수 있는 대표적인 방법 중 하나가 바로 앙상블 기법을 적용한 **랜덤포레스트(Random Forest)** 입니다.



# Random Forest

랜덤 포레스트는 분류, 회귀 분석 등에 사용되는 앙상블 학습 방법의 일종으로, 훈련 과정에서 구성한 다수의 결정 트리로부터 분류 또는 평균 예측치를 출력함으로써 동작한다.

즉, 랜덤 포레스트란 여러 개의 의사결정트리를 만들고, 투표를 시켜 다수결로 결과를 결정하는 방법이다. 



![Simple Decision Tree](images/Simple%20Decision%20Tree.PNG)



위에서는 건강 위험도를 세 가지 요소와 한가지 의사 결정 트리로 인해서 결정했습니다. 하지만, 건강 위험도를 예측하려면 세 가지 요소보다 **더 많은 요소**를 고려하는 것이 바람직할 것입니다. 성별, 키, 몸무게, 거주지역, 운동량, 기초 대사량, 근육량 등 수많은 요소도 건강에 큰 영향을 미칩니다. 위에서는 흡연 여부, 나이, 식단 세 가지 요소들로 의사 결정 트리를 생성하였지만, 다른 요소들의 조합으로 두 번째 의사 결정 트리를 생성할 수도 있습니다. 성별, 키, 흡연 여부, 근육량으로 두 번째 트리를 만들고, 키, 거주지역, 운동량으로 세 번째 트리를 만들 수도 있겠지요. (통계적으로는 독립 조건을 만들어 주기 위함입니다.)

이렇게 많은 의사 결정 트리로 ‘숲’을 만들었는데, 의견 통합이 되지 않는다면 어떻게 해야 할까요? 이 역시 현실과 비슷합니다. 의견 통합이 이루어지지 않을 경우 **다수결의 원칙**을 따르듯이, 저희의 의사 결정 ‘숲'도 **투표**로 결정을 내리게 됩니다. 1,000개의 의사 결정 트리 중 678개의 트리가 건강 위험도가 높다고 의견을 내고, 나머지는 위험도가 낮다는 의견을 냈을 경우, 숲은 그 의견들을 통합하여 건강 위험도가 높다고 하는 것이죠. 데이터 사이언스에서는 이렇게 의견을 통합하거나 여러가지 결과를 합치는 방식을 **“앙상블” (Ensemble method)**이라고 합니다.

다음은 Random Forest가 완성되는 과정입니다.

1. 30개의 주어진 요소 (predictor) 중 일부만 무작위로 선택합니다. 흡연 여부, 키, 몸무게, 나이가 선택되었다고 가정합니다.
2. 4가지 요소들 중 건강 위험도를 가장 잘 예측하는 요소 한 가지를 고릅니다. 만약 그 요소가 흡연 여부가 되었을 경우, 의사 결정 트리의 첫번째 단계가 생성됩니다.
3. 의사 결정 트리의 모든 단계를 1~2의 과정을 거쳐 생성합니다. 이렇게 한개의 트리가 생성되었습니다.
4. 3을 원하는 개수의 트리가 생성되기까지 반복합니다. 트리의 개수는 데이터 사이언티스트가 원하는 만큼 생성이 가능합니다.
5. 울창한 숲이 완성되었습니다. 숲에게 어느 한 사람에 대한 정보를 준다면, 나무들이 투표해서 한가지 의견으로 통합하여 결과를 알려줍니다.

그렇다면 왜 Random Forest는 의사 결정 트리를 만드는 데 있어 단계마다 모든 요소를 고려하지 않을까요?

그것은 역설적으로 **모든 요소를 고려하기 위함입니다**. 만약 의사 결정 트리의 한 단계를 만드는데 모든 요소를 고려한다면, 모든 의사 결정 트리가 같은 5~6개의 요소만을 가지고 생성되겠죠. 고려해야 할 요소는 30개인데, 모든 트리가 흡연 여부, 나이, 식단, 몸무게, 성별 등으로 구성되게 됩니다. 그야말로 앙상블에 금관 악기만 있고, 국회에 한가지 당만 있으며, 공대에 남자만 있는 상황과 비슷합니다. 아무리 5~6개의 요소가 가장 “똑똑한” 요소들 이어도, 나머지 25개의 “덜 똑똑한” 요소들을 고려하는 것이 목적입니다. 전교1 등한 명보다 전교5등 100명이 아는 것이 더 많은 것이랑 비슷한 원리죠.



#### 출처

https://swalloow.github.io/decison-randomforest

https://medium.com/@deepvalidation/title-3b0e263605de



